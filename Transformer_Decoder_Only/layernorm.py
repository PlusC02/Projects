# -*- coding: utf-8 -*-
"""LayerNorm.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dq-mk9d_h1U1oNmfQf0zmhznfyMRbSF6
"""

import torch
import torch.nn as nn
from torch.nn import functional as F

class LayerNorm(nn.Module):
  """
  Calculate mean along embed_dim/ Simple word: Normalize For each sample
  """
  def __init__(self, dim, eps=1e-5): # Following the same as the paper

    super(LayerNorm,self).__init__()
    self.eps = eps
    self.gamma = nn.Parameter(torch.ones(dim)) # Assume that we input (S,D) through (size(-2),size(-1))
    self.beta = nn.Parameter(torch.zeros(dim))

  def forward(self,x): #(B,S,D)
    mean = torch.mean(x,dim=-1,keepdim=True)
    var = torch.var(x,dim=-1,keepdim=True, unbiased=False)
    x_norm = (x - mean) / torch.sqrt(var + self.eps)
    self.gamma * x_norm + self.beta
    return self.gamma * x_norm + self.beta